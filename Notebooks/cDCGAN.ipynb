{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import vstack\n",
    "from numpy import asarray\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.models import load_model\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(input_shape=(128,128,3), n_classes=3):\n",
    "    # Getting the label input\n",
    "    label_input = Input(shape=(1,))\n",
    "    # embedding the label and reshaping it\n",
    "    embedded_label = Embedding(n_classes, 50)(label_input)\n",
    "    n_nodes = input_shape[0] * input_shape[1]\n",
    "    embedded_label = Dense(n_nodes)(embedded_label)\n",
    "    embedded_label = Reshape((input_shape[0], input_shape[1], 1))(embedded_label)\n",
    "    \n",
    "    # Getting the image input\n",
    "    image_input = Input(shape=input_shape)\n",
    "    # concat label to image\n",
    "    labelled_image = Concatenate()([image_input, embedded_label])\n",
    "    \n",
    "    # layer 1\n",
    "    layer_1 = Conv2D(128, (3,3), strides=(2,2), padding='same')(labelled_image)\n",
    "    layer_1 = LeakyReLU(alpha=0.2)(layer_1)\n",
    "    # layer 2\n",
    "    layer_2 = Conv2D(128, (3,3), strides=(2,2), padding='same')(layer_1)\n",
    "    layer_2 = LeakyReLU(alpha=0.2)(layer_2)\n",
    "    # layer 3\n",
    "    layer_3 = Conv2D(128, (3,3), strides=(2,2), padding='same')(layer_2)\n",
    "    layer_3 = LeakyReLU(alpha=0.2)(layer_3)\n",
    "    # layer 4\n",
    "    layer_4 = Conv2D(128, (3,3), strides=(2,2), padding='same')(layer_3)\n",
    "    layer_4 = LeakyReLU(alpha=0.2)(layer_4)\n",
    "    # layer 5\n",
    "    layer_5 = Conv2D(128, (3,3), strides=(2,2), padding='same')(layer_4)\n",
    "    layer_5 = LeakyReLU(alpha=0.2)(layer_5)\n",
    "    \n",
    "    flatten_layer = Flatten()(layer_5)\n",
    "    dropout_layer = Dropout(0.4)(flatten_layer)\n",
    "    output_layer = Dense(1, activation='sigmoid')(dropout_layer)\n",
    "    # defining the model\n",
    "    model = Model([image_input, label_input], output_layer)\n",
    "    # compiling the model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(latent_space, n_classes=3):\n",
    "    #Getting the label input\n",
    "    label_input = Input(shape=(1,))\n",
    "    # embedding the label input and reshaping it\n",
    "    embedded_layer = Embedding(n_classes, 50)(label_input)\n",
    "    n_nodes = 4 * 4\n",
    "    embedded_layer = Dense(n_nodes)(embedded_layer)\n",
    "    embedded_layer = Reshape((4, 4, 1))(embedded_layer)\n",
    "    # Getting the latent input\n",
    "    latent_input = Input(shape=(latent_space,))\n",
    "    # creating a 4*4 space\n",
    "    n_nodes = 256 * 4 * 4\n",
    "    # Creating the base image\n",
    "    base_image = Dense(n_nodes)(latent_input)\n",
    "    base_image = LeakyReLU(alpha=0.2)(base_image)\n",
    "    base_image = Reshape((4, 4, 256))(base_image)\n",
    "    # concat the base image and label input\n",
    "    labelled_base_image = Concatenate()([base_image, label_input])\n",
    "    \n",
    "    # upsampling to 8x8 image\n",
    "    layer_1 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(labelled_base_image)\n",
    "    layer_1 = LeakyReLU(alpha=0.2)(layer_1)\n",
    "    # upsampling to 16x16 image\n",
    "    layer_2 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(layer_1)\n",
    "    layer_2 = LeakyReLU(alpha=0.2)(layer_2)\n",
    "    # upsampling to 32x32 image\n",
    "    layer_3 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(layer_2)\n",
    "    layer_3 = LeakyReLU(alpha=0.2)(layer_3)\n",
    "    # upsampling to 64x64 image\n",
    "    layer_4 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(layer_3)\n",
    "    layer_4 = LeakyReLU(alpha=0.2)(layer_4)\n",
    "    #upsampling to 128x128 image\n",
    "    layer_5 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(layer_4)\n",
    "    layer_5 = LeakyReLU(alpha=0.2)(layer_5)\n",
    "    # output layer with tanh function\n",
    "    output_layer = Conv2D(3, (3, 3), activation='tanh', padding='same')(layer_5)\n",
    "    # defining the model\n",
    "    model = Model([latent_input, label_input], output_layer)\n",
    "    print(model.summary())\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(generator, discriminator):\n",
    "    # making the weights untrainable\n",
    "    discriminator.trainable = False\n",
    "    # getting the Generator noise and label inputs\n",
    "    gen_noise, gen_label = generator.input\n",
    "    # getting the Generator output image\n",
    "    gen_output = generator.output\n",
    "    # Getting the GAN output\n",
    "    # Inputting Generator output and Generator label\n",
    "    gan_output = discriminator([gen_output, gen_label])\n",
    "    # defining the GAN model\n",
    "    model = Model([gen_noise, gen_label], gan_output)\n",
    "\n",
    "    # compiling the model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples():\n",
    "\n",
    "    data_dir = 'C:\\\\Users\\\\Syed Johan Arif\\\\Desktop\\\\UM\\\\Reseach Project\\\\Plant images\\\\KD Farm\\\\bg-rm-images\\\\all_augmented4_and_original\\\\'\n",
    "    #loading the images and their labels\n",
    "    batch_size = 1\n",
    "    img_height = 128\n",
    "    img_width = 128\n",
    "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=0.1,\n",
    "        subset=\"training\",\n",
    "        seed=123,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size)\n",
    "    image_list = list()\n",
    "    label_list = list()\n",
    "    for image_batch, labels_batch in train_ds:\n",
    "        images = np.asarray(image_batch)\n",
    "        images = images.astype('float32')\n",
    "        images = (images - 127.5) / 127.5\n",
    "        image_list.append(images[0])\n",
    "        label_list.append(labels_batch.numpy())\n",
    "    image_arr = np.array(image_list)\n",
    "    label_arr = np.array(label_list)\n",
    "    return [image_arr, label_arr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    # spliting the datset into images and labels\n",
    "    images, labels = dataset\n",
    "    # selecting random image + label based on number of samples\n",
    "    ix = randint(0, images.shape[0], n_samples)\n",
    "    X, labels = images[ix], labels[ix]\n",
    "    # labeling these samples as real\n",
    "    y = ones((n_samples, 1))\n",
    "    return [X, labels], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_space, n_samples, n_classes=3):\n",
    "    # generating points in the latent space\n",
    "    x_input = randn(latent_space * n_samples)\n",
    "    # reshaping into network inputs\n",
    "    z_input = x_input.reshape(n_samples, latent_space)\n",
    "    # generating latent point labels\n",
    "    labels = randint(0, n_classes, n_samples)\n",
    "    return [z_input, labels]\n",
    " \n",
    "def generate_fake_samples(generator, latent_space, n_samples):\n",
    "    # generating points in latent space\n",
    "    z_input, labels_input = generate_latent_points(latent_space, n_samples)\n",
    "    # creating fake images\n",
    "    images = generator.predict([z_input, labels_input])\n",
    "    # labeling these samples as fake\n",
    "    y = zeros((n_samples, 1))\n",
    "    return [images, labels_input], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(examples, epoch, n=7):\n",
    "    # scale from [-1,1] to [0,1]\n",
    "    examples = (examples + 1) / 2.0\n",
    "    # plot images\n",
    "    for i in range(n * n):\n",
    "        # define subplot\n",
    "        pyplot.subplot(n, n, 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis('off')\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(examples[i])\n",
    "    # save plot to file\n",
    "    filename = 'generated_plot_v5t1_e%03d.png' % (epoch+1)\n",
    "    pyplot.savefig(filename)\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(epoch, g_model, d_model, dataset, latent_space, n_samples=150):\n",
    "    # prepare real samples\n",
    "    X_real, y_real = generate_real_samples(dataset, n_samples)\n",
    "    # evaluate discriminator on real examples\n",
    "    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
    "    # prepare fake examples\n",
    "    x_fake, y_fake = generate_fake_samples(g_model, latent_space, n_samples)\n",
    "    # evaluate discriminator on fake examples\n",
    "    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
    "    # summarize discriminator performance\n",
    "    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
    "    # save plot\n",
    "    save_plot(x_fake[0], epoch)\n",
    "    # save the generator model tile file\n",
    "    filename = 'og_augmented_generator_model_v5t1_%03d.h5' % (epoch+1)\n",
    "    g_model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(d1_hist, d2_hist, g_hist, a1_hist, a2_hist):\n",
    "    # plot loss\n",
    "    pyplot.subplot(2, 1, 1)\n",
    "    pyplot.plot(d1_hist, label='d-real')\n",
    "    pyplot.plot(d2_hist, label='d-fake')\n",
    "    pyplot.plot(g_hist, label='gen')\n",
    "    pyplot.legend()\n",
    "    # plot discriminator accuracy\n",
    "    pyplot.subplot(2, 1, 2)\n",
    "    pyplot.plot(a1_hist, label='acc-real')\n",
    "    pyplot.plot(a2_hist, label='acc-fake')\n",
    "    pyplot.legend()\n",
    "    # save plot to file\n",
    "    pyplot.savefig('plot_line_plot_loss_v5t1.png')\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, gan_model, dataset, latent_space, n_epochs=100, n_batch=8):\n",
    "    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    d1_hist, d2_hist, g_hist, a1_hist, a2_hist = list(), list(), list(), list(), list()\n",
    "    for i in range(n_epochs):\n",
    "        for j in range(bat_per_epo):\n",
    "            # getting random real samples\n",
    "            [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n",
    "            # updating discriminator model weights\n",
    "            d_loss1, d_acc1 = discriminator.train_on_batch([X_real, labels_real], y_real)\n",
    "            # generating fake samples\n",
    "            [X_fake, labels], y_fake = generate_fake_samples(generator, latent_space, half_batch)\n",
    "            # updating discriminator model weights\n",
    "            d_loss2, d_acc2 = discriminator.train_on_batch([X_fake, labels], y_fake)\n",
    "            # preparing latent input for the generator\n",
    "            [z_input, labels_input] = generate_latent_points(latent_space, n_batch)\n",
    "            # creating inverted labels for the fake samples\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            # updating the generator via the discriminator's error\n",
    "            g_loss = generator.train_on_batch([z_input, labels_input], y_gan)\n",
    "            # summarizing batch loss\n",
    "            print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f, a1=%d, a2=%d' %\n",
    "                (i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss, int(100*d_acc1), int(100*d_acc2)))\n",
    "            d1_hist.append(d_loss1)\n",
    "            d2_hist.append(d_loss2)\n",
    "            g_hist.append(g_loss)\n",
    "            a1_hist.append(d_acc1)\n",
    "            a2_hist.append(d_acc2)\n",
    "        # evaluate the model performance\n",
    "        if (i+1) % 10 == 0:\n",
    "            summarize_performance(i, generator, discriminator, dataset, latent_space)\n",
    "    plot_history(d1_hist, d2_hist, g_hist, a1_hist, a2_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the size of the latent space\n",
    "latent_space = 100\n",
    "# defining the discriminator\n",
    "discriminator = define_discriminator()\n",
    "# defining the generator\n",
    "generator = define_generator(latent_space)\n",
    "# defining the gan\n",
    "gan_model = define_gan(generator, discriminator)\n",
    "# loading image dataset\n",
    "dataset = load_real_samples()\n",
    "# training the model\n",
    "train(generator, discriminator, gan_model, dataset, latent_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating points in latent space as input for the generator\n",
    "def generate_latent_points(latent_space, n_samples, n_classes=3):\n",
    "    # generating points in the latent space\n",
    "    x_input = randn(latent_space * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    z_input = x_input.reshape(n_samples, latent_space)\n",
    "    # generating labels\n",
    "    labels = randint(0, n_classes, n_samples)\n",
    "    print(\"labels in gen function\")\n",
    "    print(labels)\n",
    "    print(type(labels))\n",
    "    return [z_input, labels]\n",
    " \n",
    "# creating a plot of generated images\n",
    "def save_plot(examples, n, n2):\n",
    "    # plot images\n",
    "    for i in range(n * n2):\n",
    "        # define subplot\n",
    "        pyplot.subplot(n, n2, 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis('off')\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(examples[i, :, :, 0])\n",
    "    pyplot.show()\n",
    "\n",
    "#loading the saved model\n",
    "model = load_model('og_augmented_generator_model_v5t1_070.h5')\n",
    "# generate images\n",
    "underweight_latent_points, labels =  generate_latent_points(100, 100)\n",
    "standardweight_latent_points, labels =  generate_latent_points(100, 100)\n",
    "overweight_latent_points, labels =  generate_latent_points(100, 100)\n",
    "\n",
    "# specify labels\n",
    "labels = asarray([x for _ in range(50) for x in range(3)])\n",
    "overweight_labels = np.full(100, 0)\n",
    "standardweight_labels = np.full(100, 1)\n",
    "underweight_labels = np.full(100, 2)\n",
    "\n",
    "\n",
    "# generating underweight images\n",
    "underweight  = model.predict([underweight_latent_points, underweight_labels])\n",
    "# scale from [-1,1] to [0,1]\n",
    "underweight = (underweight + 1) / 2.0\n",
    "# plot the result\n",
    "save_plot(underweight, 100, 1)\n",
    "\n",
    "# generating standardweight images\n",
    "standardweight  = model.predict([standardweight_latent_points, standardweight_labels])\n",
    "# scale from [-1,1] to [0,1]\n",
    "standardweight = (standardweight + 1) / 2.0\n",
    "# plot the result\n",
    "save_plot(standardweight, 100, 1)\n",
    "\n",
    "# generating overweight images\n",
    "overweight  = model.predict([overweight_latent_points, overweight_labels])\n",
    "# scale from [-1,1] to [0,1]\n",
    "overweight = (overweight + 1) / 2.0\n",
    "# plot the result\n",
    "save_plot(overweight, 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# saving synthetic underweight images\n",
    "save_underweight_images_dir = 'C:\\\\Users\\\\Syed Johan Arif\\\\Desktop\\\\Workspace\\\\Practice\\\\Generated Images\\\\final_gan_v2\\\\underweight'\n",
    "under_number = 101\n",
    "for image in underweight:\n",
    "    pyplot.imshow(image)\n",
    "    pyplot.show()\n",
    "    under_filename = save_underweight_images_dir + '\\\\cgan_image_' + str(under_number) + '.jpg'\n",
    "    im = Image.fromarray((image * 255).astype(np.uint8))\n",
    "    im = im.save(under_filename)\n",
    "    under_number = under_number + 1\n",
    "\n",
    "# saving synthetic standardweight images\n",
    "save_standardweight_images_dir = 'C:\\\\Users\\\\Syed Johan Arif\\\\Desktop\\\\Workspace\\\\Practice\\\\Generated Images\\\\final_gan_v2\\\\standardweight'\n",
    "standard_number = 101\n",
    "for image in standardweight:\n",
    "    pyplot.imshow(image)\n",
    "    pyplot.show()\n",
    "    standard_filename = save_standardweight_images_dir + '\\\\cgan_image_' + str(standard_number) + '.jpg'\n",
    "    print(standard_filename)\n",
    "    im = Image.fromarray((image * 255).astype(np.uint8))\n",
    "    im = im.save(standard_filename)\n",
    "    standard_number = standard_number + 1    \n",
    "\n",
    "# saving synthetic overweight images\n",
    "save_overweight_images_dir = 'C:\\\\Users\\\\Syed Johan Arif\\\\Desktop\\\\Workspace\\\\Practice\\\\Generated Images\\\\final_gan_v2\\\\overweight'\n",
    "over_number = 101\n",
    "for image in overweight:\n",
    "    pyplot.imshow(image)\n",
    "    pyplot.show()\n",
    "    over_filename = save_overweight_images_dir + '\\\\cgan_image_' + str(over_number) + '.jpg'\n",
    "    print(over_filename)\n",
    "    im = Image.fromarray((image * 255).astype(np.uint8))\n",
    "    im = im.save(over_filename)\n",
    "    over_number = over_number + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
